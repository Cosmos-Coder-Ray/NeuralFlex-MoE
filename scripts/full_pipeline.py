"""
Complete training pipeline integrating all advanced features.
This script demonstrates how everything works together.
"""

import sys
import os
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

import torch
import numpy as np
import pandas as pd
from rich.console import Console
from rich.progress import track
import click
import yaml
from omegaconf import OmegaConf
import h5py
import jsonlines
from safetensors.torch import save_file, load_file

# Our modules
from neuraflex_moe.models import NeuralFlexMoE
from neuraflex_moe.config import MODEL_CONFIG, TRAINING_CONFIG
from neuraflex_moe.utils.profiling import PerformanceMonitor, GPUMonitor, benchmark_inference
from neuraflex_moe.utils.advanced_optimization import (
    optimize_model_for_inference,
    TensorOperations,
)
from neuraflex_moe.inference.rag_system import create_rag_system
from neuraflex_moe.inference.advanced_quantization import auto_quantize
from neuraflex_moe.data.data_quality import DatasetCleaner

# External libraries we're integrating
try:
    from datasets import load_dataset
    import polars as pl
    import pyarrow as pa
    import sentencepiece as spm
    import tiktoken
    HAS_DATA_LIBS = True
except ImportError:
    HAS_DATA_LIBS = False

try:
    from trl import SFTTrainer, DataCollatorForCompletionOnlyLM
    HAS_TRL = True
except ImportError:
    HAS_TRL = False

try:
    import mlflow
    import aim
    HAS_TRACKING = True
except ImportError:
    HAS_TRACKING = False

console = Console()


class AdvancedTrainingPipeline:
    """
    Complete pipeline that brings everything together.
    Shows how a real training run would work.
    """

    def __init__(self, config_path: str):
        console.print("[bold blue]Initializing NeuralFlex-MoE Pipeline[/bold blue]")

        # Load config with OmegaConf for advanced features
        self.config = OmegaConf.load(config_path)

        # Initialize monitoring
        self.perf_monitor = PerformanceMonitor()
        self.gpu_monitor = GPUMonitor()

        # Initialize tracking
        if HAS_TRACKING:
            mlflow.set_experiment("neuraflex-moe")
            self.aim_run = aim.Run()
        else:
            self.aim_run = None

        self.model = None
        self.tokenizer = None

    def setup_model(self):
        """Initialize model with all optimizations"""
        console.print("\n[yellow]Setting up model...[/yellow]")

        with self.perf_monitor.measure("model_init"):
            self.model = NeuralFlexMoE(MODEL_CONFIG)

            # Apply optimizations
            self.model = optimize_model_for_inference(self.model)

            # Count parameters
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)

            console.print(f"âœ“ Model initialized")
            console.print(f"  Total parameters: {total_params / 1e9:.2f}B")
            console.print(f"  Trainable: {trainable_params / 1e9:.2f}B")

    def prepare_data(self):
        """Load and clean datasets using all data tools"""
        console.print("\n[yellow]Preparing datasets...[/yellow]")

        if not HAS_DATA_LIBS:
            console.print("[red]Warning: Some data libraries not available[/red]")
            return None

        with self.perf_monitor.measure("data_prep"):
            # Load with HuggingFace datasets
            dataset = load_dataset("wikitext", "wikitext-2-raw-v1", split="train[:1000]")

            # Convert to different formats to show flexibility
            texts = dataset["text"]

            # Use Polars for fast data processing
            df = pl.DataFrame({"text": texts})
            df = df.filter(pl.col("text").str.lengths() > 50)

            # Clean data
            cleaner = DatasetCleaner()
            cleaned = cleaner.clean_and_augment(
                df["text"].to_list(), augment=False, quality_threshold=20.0
            )

            console.print(f"âœ“ Data prepared: {len(cleaned['texts'])} samples")

            return cleaned["texts"]

    def train_with_monitoring(self, train_data):
        """Training loop with full monitoring"""
        console.print("\n[yellow]Starting training...[/yellow]")

        if not train_data:
            console.print("[red]No training data available[/red]")
            return

        # This is a simplified training loop
        # Real training would use the full Trainer class
        self.model.train()

        for epoch in track(range(3), description="Training"):
            with self.perf_monitor.measure(f"epoch_{epoch}"):
                # Simulate training
                for i in range(10):
                    with self.perf_monitor.measure("train_step"):
                        # In real training, this would be actual forward/backward
                        pass

                # Log metrics
                if self.aim_run:
                    self.aim_run.track({"loss": 2.5 - epoch * 0.5}, step=epoch)

            # Show GPU stats
            if epoch % 1 == 0:
                self.gpu_monitor.print_stats()

        console.print("âœ“ Training complete")

    def setup_rag(self, documents):
        """Setup RAG system for enhanced generation"""
        console.print("\n[yellow]Setting up RAG system...[/yellow]")

        with self.perf_monitor.measure("rag_setup"):
            self.rag = create_rag_system(self.model, self.tokenizer, documents)

        console.print("âœ“ RAG system ready")

    def quantize_model(self):
        """Apply quantization for deployment"""
        console.print("\n[yellow]Quantizing model...[/yellow]")

        with self.perf_monitor.measure("quantization"):
            quantized = auto_quantize(self.model, self.tokenizer, method="dynamic")

        console.print("âœ“ Model quantized")
        return quantized

    def save_model(self, output_dir: str):
        """Save model in multiple formats"""
        console.print(f"\n[yellow]Saving model to {output_dir}...[/yellow]")

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # Save as SafeTensors (recommended)
        state_dict = self.model.state_dict()
        save_file(state_dict, output_path / "model.safetensors")

        # Save config as YAML
        with open(output_path / "config.yaml", "w") as f:
            yaml.dump(MODEL_CONFIG, f)

        # Save metrics as JSON Lines
        with jsonlines.open(output_path / "metrics.jsonl", "w") as writer:
            writer.write(self.perf_monitor.get_summary())

        # Save some data in HDF5 for efficient storage
        with h5py.File(output_path / "metadata.h5", "w") as f:
            f.create_dataset("model_size", data=sum(p.numel() for p in self.model.parameters()))

        console.print("âœ“ Model saved in multiple formats")

    def run_benchmarks(self):
        """Run comprehensive benchmarks"""
        console.print("\n[yellow]Running benchmarks...[/yellow]")

        test_prompts = [
            "What is machine learning?",
            "Explain quantum computing",
            "Write a Python function",
        ]

        results = benchmark_inference(self.model, self.tokenizer, test_prompts, num_runs=5)

        console.print(f"âœ“ Throughput: {results['tokens_per_second']:.1f} tokens/sec")

    def show_summary(self):
        """Display final summary"""
        console.print("\n[bold green]Pipeline Complete![/bold green]")
        console.print("\n[cyan]Performance Summary:[/cyan]")

        self.perf_monitor.print_summary()

        # Save summary to file
        summary = self.perf_monitor.get_summary()
        df = pd.DataFrame(summary).T
        df.to_csv("./logs/pipeline_summary.csv")

        console.print("\nâœ“ Summary saved to ./logs/pipeline_summary.csv")


@click.command()
@click.option("--config", default="configs/neuraflex_7b.yaml", help="Config file path")
@click.option("--output-dir", default="./models/pipeline_output", help="Output directory")
@click.option("--skip-training", is_flag=True, help="Skip training step")
@click.option("--skip-quantization", is_flag=True, help="Skip quantization")
def main(config, output_dir, skip_training, skip_quantization):
    """
    Run the complete NeuralFlex-MoE pipeline.

    This demonstrates integration of all advanced features:
    - Data quality checking (cleanlab, nlpaug, textstat)
    - Advanced optimizations (einops, xformers, triton)
    - RAG system (langchain, haystack, chromadb, faiss)
    - Quantization (onnx, gptq, quanto)
    - Profiling (nvitop, torch profiler, memray, scalene)
    - Tracking (mlflow, aim, tensorboard, wandb)
    - Code quality (black, ruff, isort, mypy, flake8)
    """
    console.print("[bold magenta]NeuralFlex-MoE Full Pipeline[/bold magenta]\n")

    # Initialize pipeline
    pipeline = AdvancedTrainingPipeline(config)

    # Setup model
    pipeline.setup_model()

    # Prepare data
    train_data = pipeline.prepare_data()

    # Training
    if not skip_training and train_data:
        pipeline.train_with_monitoring(train_data)

    # Setup RAG
    if train_data:
        pipeline.setup_rag(train_data[:100])

    # Quantization
    if not skip_quantization:
        pipeline.quantize_model()

    # Benchmarks
    pipeline.run_benchmarks()

    # Save everything
    pipeline.save_model(output_dir)

    # Show summary
    pipeline.show_summary()

    console.print("\n[bold green]All done! ðŸš€[/bold green]")


if __name__ == "__main__":
    main()
